{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81555523-f9de-48c9-9d9d-e3e8c091b38d",
   "metadata": {},
   "source": [
    "## Text Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c756e4-0e91-45e4-87f9-95b65ef8c112",
   "metadata": {},
   "source": [
    "1) Extract Sample document and apply following document preprocessing methods: Tokenization, POS Tagging, stop words removal, Stemming and Lemmatization.\n",
    "2) Create representation of document by calculating Term Frequency and Inverse Document Frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e9660483-93cf-4cd2-873b-43fad5d890e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9836085e-5aec-495b-9ac5-87c7109890f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\saksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\saksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\saksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary tools\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "30759f1d-d8d3-476d-a633-f819e7bdae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2c9643-381f-4858-9173-cbb7521d67f0",
   "metadata": {},
   "source": [
    "### Read Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "93ba0410-10af-44d4-954f-dfa4b2a5e5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python is a high-level, interpreted programming language created by guido van rossum and first released in 1991. it is designed with an emphasis on code readability, and its syntax allows programmers to express concepts in fewer lines of code than would be possible in languages such as c++ or java.\\n\\npython supports multiple programming paradigms, including procedural, object-oriented, and functional programming. in simpler terms, this means its flexible and allows you to write code in different ways, whether that's like giving the computer a to-do list (procedural), creating digital models of things or concepts (object-oriented), or treating your code like a math problem (functional).\n"
     ]
    }
   ],
   "source": [
    "text = open('../Datasets/SampleText.txt', 'r')\n",
    "text = text.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efa90b8-c571-4098-b009-4acfa612b4bb",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "- Breaking a text into smaller units, typically words or phrases, to facilitate further analysis.\n",
    "- Word Tokenization : splits a piece of text into individual words based on a certain delimiter\n",
    "- Character Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dc8b1b53-da1e-44ee-bd29-62b46ea35c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'is', 'a', 'high-level', ',', 'interpreted', 'programming', 'language', 'created', 'by', 'guido', 'van', 'rossum', 'and', 'first', 'released', 'in', '1991.', 'it', 'is', 'designed', 'with', 'an', 'emphasis', 'on', 'code', 'readability', ',', 'and', 'its', 'syntax', 'allows', 'programmers', 'to', 'express', 'concepts', 'in', 'fewer', 'lines', 'of', 'code', 'than', 'would', 'be', 'possible', 'in', 'languages', 'such', 'as', 'c++', 'or', 'java.\\\\n\\\\npython', 'supports', 'multiple', 'programming', 'paradigms', ',', 'including', 'procedural', ',', 'object-oriented', ',', 'and', 'functional', 'programming', '.', 'in', 'simpler', 'terms', ',', 'this', 'means', 'its', 'flexible', 'and', 'allows', 'you', 'to', 'write', 'code', 'in', 'different', 'ways', ',', 'whether', 'that', \"'s\", 'like', 'giving', 'the', 'computer', 'a', 'to-do', 'list', '(', 'procedural', ')', ',', 'creating', 'digital', 'models', 'of', 'things', 'or', 'concepts', '(', 'object-oriented', ')', ',', 'or', 'treating', 'your', 'code', 'like', 'a', 'math', 'problem', '(', 'functional', ')', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0d4dcf-6220-443f-ab30-820fcd99c9bf",
   "metadata": {},
   "source": [
    "### POS (Parts of Speech) Tagging\n",
    "- Assigning grammatical categories (like noun, verb, adjective) to each word in a text based on its context and meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eea8a11f-6227-488e-835e-5ad8d63637d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('python', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('high-level', 'JJ'), (',', ','), ('interpreted', 'JJ'), ('programming', 'NN'), ('language', 'NN'), ('created', 'VBN'), ('by', 'IN'), ('guido', 'NN'), ('van', 'NN'), ('rossum', 'NN'), ('and', 'CC'), ('first', 'JJ'), ('released', 'VBN'), ('in', 'IN'), ('1991.', 'CD'), ('it', 'PRP'), ('is', 'VBZ'), ('designed', 'VBN'), ('with', 'IN'), ('an', 'DT'), ('emphasis', 'NN'), ('on', 'IN'), ('code', 'NN'), ('readability', 'NN'), (',', ','), ('and', 'CC'), ('its', 'PRP$'), ('syntax', 'NN'), ('allows', 'VBZ'), ('programmers', 'NNS'), ('to', 'TO'), ('express', 'VB'), ('concepts', 'NNS'), ('in', 'IN'), ('fewer', 'JJR'), ('lines', 'NNS'), ('of', 'IN'), ('code', 'NN'), ('than', 'IN'), ('would', 'MD'), ('be', 'VB'), ('possible', 'JJ'), ('in', 'IN'), ('languages', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('c++', 'NN'), ('or', 'CC'), ('java.\\\\n\\\\npython', 'NN'), ('supports', 'NNS'), ('multiple', 'JJ'), ('programming', 'VBG'), ('paradigms', 'NN'), (',', ','), ('including', 'VBG'), ('procedural', 'JJ'), (',', ','), ('object-oriented', 'JJ'), (',', ','), ('and', 'CC'), ('functional', 'JJ'), ('programming', 'NN'), ('.', '.'), ('in', 'IN'), ('simpler', 'NN'), ('terms', 'NNS'), (',', ','), ('this', 'DT'), ('means', 'VBZ'), ('its', 'PRP$'), ('flexible', 'JJ'), ('and', 'CC'), ('allows', 'VBZ'), ('you', 'PRP'), ('to', 'TO'), ('write', 'VB'), ('code', 'NN'), ('in', 'IN'), ('different', 'JJ'), ('ways', 'NNS'), (',', ','), ('whether', 'IN'), ('that', 'DT'), (\"'s\", 'VBZ'), ('like', 'IN'), ('giving', 'VBG'), ('the', 'DT'), ('computer', 'NN'), ('a', 'DT'), ('to-do', 'JJ'), ('list', 'NN'), ('(', '('), ('procedural', 'JJ'), (')', ')'), (',', ','), ('creating', 'VBG'), ('digital', 'JJ'), ('models', 'NNS'), ('of', 'IN'), ('things', 'NNS'), ('or', 'CC'), ('concepts', 'NNS'), ('(', '('), ('object-oriented', 'JJ'), (')', ')'), (',', ','), ('or', 'CC'), ('treating', 'VBG'), ('your', 'PRP$'), ('code', 'NN'), ('like', 'IN'), ('a', 'DT'), ('math', 'NN'), ('problem', 'NN'), ('(', '('), ('functional', 'JJ'), (')', ')'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "pos_tags = nltk.pos_tag(tokens)\n",
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bfcf52-081e-4367-9fcd-86c539def036",
   "metadata": {},
   "source": [
    "### Stop Words Removal\n",
    "- Eliminating common words (like \"the\", \"is\", \"and\") from a text\n",
    "- dosen't carry significant meaning for analysis purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ff1e1216-d3f4-4da4-a4d0-cfe666fa4f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Tokens: ['python', 'high-level', ',', 'interpreted', 'programming', 'language', 'created', 'guido', 'van', 'rossum', 'first', 'released', '1991.', 'designed', 'emphasis', 'code', 'readability', ',', 'syntax', 'allows', 'programmers', 'express', 'concepts', 'fewer', 'lines', 'code', 'would', 'possible', 'languages', 'c++', 'java.\\\\n\\\\npython', 'supports', 'multiple', 'programming', 'paradigms', ',', 'including', 'procedural', ',', 'object-oriented', ',', 'functional', 'programming', '.', 'simpler', 'terms', ',', 'means', 'flexible', 'allows', 'write', 'code', 'different', 'ways', ',', 'whether', \"'s\", 'like', 'giving', 'computer', 'to-do', 'list', '(', 'procedural', ')', ',', 'creating', 'digital', 'models', 'things', 'concepts', '(', 'object-oriented', ')', ',', 'treating', 'code', 'like', 'math', 'problem', '(', 'functional', ')', '.']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = []\n",
    "\n",
    "for word in tokens:\n",
    "    lower_word = word.lower()\n",
    "    if lower_word not in stop_words:\n",
    "        filtered_tokens.append(word)\n",
    "print(\"Filtered Tokens:\", filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9d7942ff-ed5f-4e0b-8f12-376897475afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'high-level', 'interpreted', 'programming', 'language', 'created', 'guido', 'van', 'rossum', 'first', 'released', '1991.', 'designed', 'emphasis', 'code', 'readability', 'syntax', 'allows', 'programmers', 'express', 'concepts', 'fewer', 'lines', 'code', 'would', 'possible', 'languages', 'c++', 'java.\\\\n\\\\npython', 'supports', 'multiple', 'programming', 'paradigms', 'including', 'procedural', 'object-oriented', 'functional', 'programming', 'simpler', 'terms', 'means', 'flexible', 'allows', 'write', 'code', 'different', 'ways', 'whether', \"'s\", 'like', 'giving', 'computer', 'to-do', 'list', 'procedural', 'creating', 'digital', 'models', 'things', 'concepts', 'object-oriented', 'treating', 'code', 'like', 'math', 'problem', 'functional']\n"
     ]
    }
   ],
   "source": [
    "# Puncuation Removal\n",
    "new_filtered_tokens = []\n",
    "\n",
    "for word in filtered_tokens:\n",
    "    if word not in string.punctuation:\n",
    "        new_filtered_tokens.append(word)\n",
    "\n",
    "print(new_filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48caa1c2-3117-4d75-b983-6b55ef6bb6ae",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "- Reducing words to their base or root form, typically by removing suffixes, to normalize variations of words.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d463fc3a-97e9-4d3a-8613-e2cab5c84204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'high-level', 'interpret', 'program', 'languag', 'creat', 'guido', 'van', 'rossum', 'first', 'releas', '1991.', 'design', 'emphasi', 'code', 'readabl', 'syntax', 'allow', 'programm', 'express', 'concept', 'fewer', 'line', 'code', 'would', 'possibl', 'languag', 'c++', 'java.\\\\n\\\\npython', 'support', 'multipl', 'program', 'paradigm', 'includ', 'procedur', 'object-ori', 'function', 'program', 'simpler', 'term', 'mean', 'flexibl', 'allow', 'write', 'code', 'differ', 'way', 'whether', \"'s\", 'like', 'give', 'comput', 'to-do', 'list', 'procedur', 'creat', 'digit', 'model', 'thing', 'concept', 'object-ori', 'treat', 'code', 'like', 'math', 'problem', 'function']\n"
     ]
    }
   ],
   "source": [
    "porter = PorterStemmer()\n",
    "\n",
    "stemmed_words = []\n",
    "\n",
    "for word in new_filtered_tokens:\n",
    "    stem = porter.stem(word)\n",
    "    stemmed_words.append(stem)\n",
    "\n",
    "print(stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7721464b-18d5-45dc-bdaa-4d8fec5ab32d",
   "metadata": {},
   "source": [
    "### Lemmetization\n",
    "- Similar to stemming but aims to return the base or dictionary form of a word (lemma), considering its morphological variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "12a6b911-e082-4529-9aa1-06d1e9e082c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'high-level', 'interpreted', 'programming', 'language', 'created', 'guido', 'van', 'rossum', 'first', 'released', '1991.', 'designed', 'emphasis', 'code', 'readability', 'syntax', 'allows', 'programmer', 'express', 'concept', 'fewer', 'line', 'code', 'would', 'possible', 'language', 'c++', 'java.\\\\n\\\\npython', 'support', 'multiple', 'programming', 'paradigm', 'including', 'procedural', 'object-oriented', 'functional', 'programming', 'simpler', 'term', 'mean', 'flexible', 'allows', 'write', 'code', 'different', 'way', 'whether', \"'s\", 'like', 'giving', 'computer', 'to-do', 'list', 'procedural', 'creating', 'digital', 'model', 'thing', 'concept', 'object-oriented', 'treating', 'code', 'like', 'math', 'problem', 'functional']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = []\n",
    "\n",
    "for word in new_filtered_tokens:\n",
    "    lemma = lemmatizer.lemmatize(word)\n",
    "    lemmatized_words.append(lemma)\n",
    "\n",
    "print(lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8791b0eb-bbb0-43b1-914b-05606e411267",
   "metadata": {},
   "source": [
    "## Representation of Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25efda9f-58cc-4b32-bd51-6f19d742fed1",
   "metadata": {},
   "source": [
    "#### Term Frequency (TF)\n",
    "Measuring how frequently a term occurs in a document relative to the total number of terms in that document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dce2027d-580d-414d-9a93-39845d5f7a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Frequency: <FreqDist with 56 samples and 67 outcomes>\n",
      "Term Frequency:\n",
      "python: 1\n",
      "high-level: 1\n",
      "interpreted: 1\n",
      "programming: 3\n",
      "language: 1\n",
      "created: 1\n",
      "guido: 1\n",
      "van: 1\n",
      "rossum: 1\n",
      "first: 1\n",
      "released: 1\n",
      "1991.: 1\n",
      "designed: 1\n",
      "emphasis: 1\n",
      "code: 4\n",
      "readability: 1\n",
      "syntax: 1\n",
      "allows: 2\n",
      "programmers: 1\n",
      "express: 1\n",
      "concepts: 2\n",
      "fewer: 1\n",
      "lines: 1\n",
      "would: 1\n",
      "possible: 1\n",
      "languages: 1\n",
      "c++: 1\n",
      "java.\\n\\npython: 1\n",
      "supports: 1\n",
      "multiple: 1\n",
      "paradigms: 1\n",
      "including: 1\n",
      "procedural: 2\n",
      "object-oriented: 2\n",
      "functional: 2\n",
      "simpler: 1\n",
      "terms: 1\n",
      "means: 1\n",
      "flexible: 1\n",
      "write: 1\n",
      "different: 1\n",
      "ways: 1\n",
      "whether: 1\n",
      "'s: 1\n",
      "like: 2\n",
      "giving: 1\n",
      "computer: 1\n",
      "to-do: 1\n",
      "list: 1\n",
      "creating: 1\n",
      "digital: 1\n",
      "models: 1\n",
      "things: 1\n",
      "treating: 1\n",
      "math: 1\n",
      "problem: 1\n"
     ]
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "tf = FreqDist(new_filtered_tokens)\n",
    "print(\"Term Frequency:\", tf)\n",
    "\n",
    "# Display Output\n",
    "print(\"Term Frequency:\")\n",
    "for word, freq in tf.items():\n",
    "    print(f\"{word}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b485c4-9248-436d-be92-cf22c459714f",
   "metadata": {},
   "source": [
    "#### Inverse Document Frequency (IDF)\n",
    "Measuring the rarity or commonness of a term across all documents in a corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1f0032e6-dce4-4339-8ebb-f9efcc297a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF: {'python': 1.0, 'high-level': 1.0, 'interpreted': 1.0, 'programming': 3.0, 'language': 1.0, 'created': 1.0, 'guido': 1.0, 'van': 1.0, 'rossum': 1.0, 'first': 1.0, 'released': 1.0, '1991.': 1.0, 'designed': 1.0, 'emphasis': 1.0, 'code': 4.0, 'readability': 1.0, 'syntax': 1.0, 'allows': 2.0, 'programmers': 1.0, 'express': 1.0, 'concepts': 2.0, 'fewer': 1.0, 'lines': 1.0, 'would': 1.0, 'possible': 1.0, 'languages': 1.0, 'c++': 1.0, 'java.\\\\n\\\\npython': 1.0, 'supports': 1.0, 'multiple': 1.0, 'paradigms': 1.0, 'including': 1.0, 'procedural': 2.0, 'object-oriented': 2.0, 'functional': 2.0, 'simpler': 1.0, 'terms': 1.0, 'means': 1.0, 'flexible': 1.0, 'write': 1.0, 'different': 1.0, 'ways': 1.0, 'whether': 1.0, \"'s\": 1.0, 'like': 2.0, 'giving': 1.0, 'computer': 1.0, 'to-do': 1.0, 'list': 1.0, 'creating': 1.0, 'digital': 1.0, 'models': 1.0, 'things': 1.0, 'treating': 1.0, 'math': 1.0, 'problem': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [text]\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(corpus)\n",
    "idf = tfidf_vectorizer.idf_\n",
    "\n",
    "tfidf = {}\n",
    "\n",
    "for i, freq in tf.items():\n",
    "    tfidf_value = freq * idf[]  \n",
    "    tfidf[word] = float(tfidf_value)\n",
    "\n",
    "print(\"TF-IDF:\", tfidf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
